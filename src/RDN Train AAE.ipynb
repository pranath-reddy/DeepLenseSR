{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30364,"status":"ok","timestamp":1686269110487,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"uV8Lch-wnW32","outputId":"d856af64-80f3-450a-d825-d5187cbd2207"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1686269110488,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"Fltk46feoNyW","outputId":"e5ffbdb4-1581-4cd4-8938-47403553a1a8"},"outputs":[],"source":["# cd drive/My \\Drive/....."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["64d150705e32485098abf0a44ddaf1dc","a49354cc11da4c3bb26de58ce5022543","03f3256c714c4e6dad5c395bde93b808","3d25215677b7433395cdb4edf77dbe5a","f64e7e72da5d40c18eb1e34b6cdf7771","1e017e5c44994cdfa6d3b00eb70e2ac9","7c191f7bf8d447f39663c9153be4e831","ce5938fd72a241cbb18e65f37cebc0dc","7e5cdc59d335454bac8c4107ec39ec88","7ff6cca6d692403986f34dd4330a8a04","c217701ebc034819a4cf923d147f2217"]},"executionInfo":{"elapsed":18021743,"status":"ok","timestamp":1686288431607,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"agXdpFwPPiHw","outputId":"c1fc8459-a1d2-4d4d-d6a1-d0a94825b051"},"outputs":[],"source":["'''\n","Pranath Reddy\n","Benchmark Notebook for Superresolution\n","Model: Residual Dense Network (RDN)\n","'''\n","\n","# Import required libraries\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from tqdm.notebook import tqdm\n","from torch import autograd\n","from torchvision import models\n","import torch.utils.model_zoo as model_zoo\n","import math\n","from skimage.metrics import structural_similarity as ssim\n","from sklearn.utils import shuffle\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch.nn.functional as F\n","\n","# Load training data\n","# High-Resolution lensing data\n","x_trainHR = np.load('./Data/train_HR.npy').astype(np.float32).reshape(-1,1,150,150) \n","# Low-Resolution lensing data\n","x_trainLR = np.load('./Data/train_LR.npy').astype(np.float32).reshape(-1,1,75,75)\n","x_trainHR = torch.Tensor(x_trainHR)\n","x_trainLR = torch.Tensor(x_trainLR)\n","# Print data dimensions\n","print(x_trainHR.shape)\n","print(x_trainLR.shape)\n","\n","# Create dataset and dataloader for efficient data loading and batching\n","dataset = TensorDataset(x_trainLR, x_trainHR)\n","dataloader = DataLoader(dataset, batch_size=8)\n","\n","# Define DenseLayer class, which represents a single dense layer\n","class DenseLayer(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DenseLayer, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=3 // 2)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        return torch.cat([x, self.relu(self.conv(x))], 1)\n","\n","# Define RDB (Residual Dense Block) class\n","class RDB(nn.Module):\n","    def __init__(self, in_channels, growth_rate, num_layers):\n","        super(RDB, self).__init__()\n","        self.layers = nn.Sequential(*[DenseLayer(in_channels + growth_rate * i, growth_rate) for i in range(num_layers)])\n","\n","        # local feature fusion\n","        self.lff = nn.Conv2d(in_channels + growth_rate * num_layers, growth_rate, kernel_size=1)\n","\n","    def forward(self, x):\n","        # local residual learning\n","        return x + self.lff(self.layers(x))  \n","\n","# Define RDN (Residual Dense Network) class\n","class RDN(nn.Module):\n","    def __init__(self, scale_factor=2, num_channels=1, num_features=32, growth_rate=32, num_blocks=6, num_layers=4):\n","        super(RDN, self).__init__()\n","        self.G0 = num_features\n","        self.G = growth_rate\n","        self.D = num_blocks\n","        self.C = num_layers\n","\n","        # shallow feature extraction\n","        self.sfe1 = nn.Conv2d(num_channels, num_features, kernel_size=3, padding=3 // 2)\n","        self.sfe2 = nn.Conv2d(num_features, num_features, kernel_size=3, padding=3 // 2)\n","\n","        # residual dense blocks\n","        self.rdbs = nn.ModuleList([RDB(self.G0, self.G, self.C)])\n","        for _ in range(self.D - 1):\n","            self.rdbs.append(RDB(self.G, self.G, self.C))\n","\n","        # global feature fusion\n","        self.gff = nn.Sequential(\n","            nn.Conv2d(self.G * self.D, self.G0, kernel_size=1),\n","            nn.Conv2d(self.G0, self.G0, kernel_size=3, padding=3 // 2)\n","        )\n","\n","        # up-sampling\n","        assert 2 <= scale_factor <= 4\n","        if scale_factor == 2 or scale_factor == 4:\n","            self.upscale = []\n","            for _ in range(scale_factor // 2):\n","                self.upscale.extend([nn.Conv2d(self.G0, self.G0 * (2 ** 2), kernel_size=3, padding=3 // 2),\n","                                     nn.PixelShuffle(2)])\n","            self.upscale = nn.Sequential(*self.upscale)\n","        else:\n","            self.upscale = nn.Sequential(\n","                nn.Conv2d(self.G0, self.G0 * (scale_factor ** 2), kernel_size=3, padding=3 // 2),\n","                nn.PixelShuffle(scale_factor)\n","            )\n","\n","        self.output = nn.Conv2d(self.G0, num_channels, kernel_size=3, padding=3 // 2)\n","\n","    def forward(self, x):\n","        sfe1 = self.sfe1(x)\n","        sfe2 = self.sfe2(sfe1)\n","\n","        x = sfe2\n","        local_features = []\n","        for i in range(self.D):\n","            x = self.rdbs[i](x)\n","            local_features.append(x)\n","\n","        # global residual learning\n","        x = self.gff(torch.cat(local_features, 1)) + sfe1  \n","        x = self.upscale(x)\n","        x = self.output(x)\n","        return x\n","\n","# Set the device to use for training\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Pass the model to the device\n","model = RDN().to(device)\n","\n","# Load the pre-trained AAE model \n","class Encoder(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv2d(1, 16, 7, stride=3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, 7, stride=3, padding=1)\n","        self.conv3 = nn.Conv2d(32, 64, 7)\n","        self.flat = nn.Flatten()\n","        self.linear = nn.Linear(5184, 1000)\n","\n","    def forward(self, x):\n","        \n","        convolution1 = F.relu(self.conv1(x))\n","        convolution2 = F.relu(self.conv2(convolution1))\n","        convolution3 = F.relu(self.conv3(convolution2))\n","        Flattened = self.flat(convolution3)\n","        z = self.linear(Flattened)\n","\n","        return z\n","        \n","class Decoder(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.linear = nn.Linear(1000, 5184)\n","        self.conv4 = nn.ConvTranspose2d(64, 32, 7)\n","        self.conv5 = nn.ConvTranspose2d(32, 16, 7, stride=3, padding=1, output_padding=2)\n","        self.conv6 = nn.ConvTranspose2d(16, 1, 6, stride=3, padding=1, output_padding=2)\n","\n","    def forward(self, x):\n","\n","        hidden = self.linear(x)\n","        Reshaped = hidden.reshape(-1,64,9,9)\n","        convolution4 = F.relu(self.conv4(Reshaped))\n","        convolution5 = F.relu(self.conv5(convolution4))\n","        predicted = torch.tanh(self.conv6(convolution5))\n","\n","        return predicted\n","\n","encoder = torch.load('./Weights/AAE/AAE_Enc.pth', map_location=torch.device('cuda'))\n","decoder = torch.load('./Weights/AAE/AAE_Dec.pth', map_location=torch.device('cuda'))\n","for param in encoder.parameters():\n","    param.requires_grad = False\n","for param in decoder.parameters():\n","    param.requires_grad = False\n","\n","class CombinedLoss(nn.Module):\n","    def __init__(self, encoder, decoder, alpha=0.5):\n","        super(CombinedLoss, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.mse_loss = nn.MSELoss()\n","        self.alpha = alpha\n","\n","    def forward(self, x, y):\n","        x_aae, y_aae = self.decoder(self.encoder(x)), self.decoder(self.encoder(y))\n","        content_loss = self.mse_loss(x_aae, y_aae)\n","        mse_loss = self.mse_loss(x, y)\n","        loss = self.alpha * content_loss + (1 - self.alpha) * mse_loss\n","        return loss\n","\n","criteria = CombinedLoss(encoder, decoder)\n","optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n","\n","# Set the number of training epochs and learning rate scheduler\n","n_epochs = 100\n","scheduler = optim.lr_scheduler.OneCycleLR(optimizer, 2e-4, epochs=n_epochs, steps_per_epoch=x_trainHR.shape[0])\n","\n","# Training loop\n","loss_array = []\n","for epoch in tqdm(range(1, n_epochs+1)):\n","    train_loss = 0.0\n","    \n","    for data in dataloader:\n","\n","        # Fetch HR, LR data and pass to device\n","        datalr = data[0]\n","        datahr = data[1]\n","        datalr = datalr.to(device)\n","        datahr = datahr.to(device)\n","\n","        # Forward pass: compute predicted outputs by passing inputs to the model\n","        outputs = model(datalr)\n","        # Calculate the loss\n","        loss = criteria(outputs, datahr)\n","\n","        # Reset the gradients\n","        optimizer.zero_grad()\n","        # Perform a backward pass (backpropagation)\n","        loss.backward()\n","        # Update the parameters\n","        optimizer.step()\n","        # Update the learning rate\n","        scheduler.step()\n","\n","         # Update the training loss\n","        train_loss += (loss.item()*datahr.size(0))\n","        \n","    # Print average training statistics\n","    train_loss = train_loss/x_trainHR.shape[0]\n","    loss_array.append(train_loss)\n","\n","    # Save model and training loss\n","    torch.save(model, './Weights/RDN_AAE.pth')\n","    np.save('Results/RDN_Loss_aae.npy', loss_array)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03f3256c714c4e6dad5c395bde93b808":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce5938fd72a241cbb18e65f37cebc0dc","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e5cdc59d335454bac8c4107ec39ec88","value":100}},"1e017e5c44994cdfa6d3b00eb70e2ac9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d25215677b7433395cdb4edf77dbe5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ff6cca6d692403986f34dd4330a8a04","placeholder":"​","style":"IPY_MODEL_c217701ebc034819a4cf923d147f2217","value":" 100/100 [5:20:25&lt;00:00, 192.32s/it]"}},"64d150705e32485098abf0a44ddaf1dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a49354cc11da4c3bb26de58ce5022543","IPY_MODEL_03f3256c714c4e6dad5c395bde93b808","IPY_MODEL_3d25215677b7433395cdb4edf77dbe5a"],"layout":"IPY_MODEL_f64e7e72da5d40c18eb1e34b6cdf7771"}},"7c191f7bf8d447f39663c9153be4e831":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e5cdc59d335454bac8c4107ec39ec88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ff6cca6d692403986f34dd4330a8a04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a49354cc11da4c3bb26de58ce5022543":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e017e5c44994cdfa6d3b00eb70e2ac9","placeholder":"​","style":"IPY_MODEL_7c191f7bf8d447f39663c9153be4e831","value":"100%"}},"c217701ebc034819a4cf923d147f2217":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce5938fd72a241cbb18e65f37cebc0dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f64e7e72da5d40c18eb1e34b6cdf7771":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
