{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uV8Lch-wnW32"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fltk46feoNyW"},"outputs":[],"source":["# cd drive/My \\Drive/....."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","id":"agXdpFwPPiHw"},"outputs":[],"source":["'''\n","Pranath Reddy\n","Benchmark Notebook for Superresolution\n","Model: RCAN\n","'''\n","\n","# Import required libraries\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from tqdm.notebook import tqdm\n","from torch import autograd\n","from torchvision import models\n","import torch.utils.model_zoo as model_zoo\n","import math\n","from skimage.metrics import structural_similarity as ssim\n","from sklearn.utils import shuffle\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Load training data\n","x_trainHR = np.load('./Data/train_HR.npy').astype(np.float32).reshape(-1,1,150,150) \n","x_trainLR = np.load('./Data/train_LR.npy').astype(np.float32).reshape(-1,1,75,75)\n","x_trainHR = torch.Tensor(x_trainHR)\n","x_trainLR = torch.Tensor(x_trainLR)\n","print(x_trainHR.shape)\n","print(x_trainLR.shape)\n","\n","dataset = TensorDataset(x_trainLR, x_trainHR)\n","dataloader = DataLoader(dataset, batch_size=8)\n","\n","# Channel Attention (CA) Layer\n","class CALayer(nn.Module):\n","    def __init__(self, channel, reduction=16):\n","        super(CALayer, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.ca = nn.Sequential(\n","                nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=True),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=True),\n","                nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        y = self.avg_pool(x)\n","        y = self.ca(y)\n","        return x * y\n","\n","# Residual Channel Attention Block (RCAB)\n","class RCAB(nn.Module):\n","    def __init__(self, channel, reduction=16):\n","        super(RCAB, self).__init__()\n","        self.body = nn.Sequential(\n","            nn.Conv2d(channel, channel, 3, 1, 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(channel, channel, 3, 1, 1),\n","            CALayer(channel, reduction)\n","        )\n","\n","    def forward(self, x):\n","        res = self.body(x)\n","        res += x\n","        return res\n","\n","# Residual Group (RG)\n","class RG(nn.Module):\n","    def __init__(self, channel, num_rcab, reduction):\n","        super(RG, self).__init__()\n","        modules_body = [RCAB(channel, reduction) for _ in range(num_rcab)]\n","        modules_body.append(nn.Conv2d(channel, channel, 3, padding=1))\n","        self.body = nn.Sequential(*modules_body)\n","\n","    def forward(self, x):\n","        res = self.body(x)\n","        res += x\n","        return res\n","\n","# Residual Channel Attention Network (RCAN)\n","class RCAN(nn.Module):\n","    def __init__(self, num_rg=2, num_rcab=4, num_channels=1, num_features=64, scale_factor=2, reduction=16):\n","        super(RCAN, self).__init__()\n","        self.sf = scale_factor\n","        self.num_features = num_features\n","\n","        self.head = nn.Conv2d(num_channels, num_features, 3, padding=1)\n","\n","        self.body = nn.Sequential(*[RG(num_features, num_rcab, reduction) for _ in range(num_rg)])\n","\n","        self.tail = nn.Sequential(\n","            nn.Conv2d(num_features, num_features, 3, padding=1),\n","            nn.Conv2d(num_features, num_channels * (scale_factor ** 2), 3, padding=1),\n","            nn.PixelShuffle(scale_factor)\n","        )\n","\n","    def forward(self, x):\n","        x = self.head(x)\n","        res = self.body(x)\n","        res += x\n","        x = self.tail(res)\n","        return x\n","    \n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n","            nn.Flatten(),\n","            nn.Linear(36, 1),  \n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","\n","device = torch.device(\"mps\")\n","model = RCAN().to(device)\n","discriminator = Discriminator().to(device)\n","\n","# Define the optimizers\n","optimizer_G = torch.optim.Adam(model.parameters(), lr=2e-4)\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=2e-4)\n","\n","# Define the loss functions\n","criterion_GAN = torch.nn.BCELoss().to(device)\n","criterion_content = torch.nn.L1Loss().to(device)\n","\n","# Define the real and fake labels\n","real_label = 1.\n","fake_label = 0.\n","\n","n_epochs = 30\n","\n","# Training\n","for epoch in tqdm(range(1, n_epochs+1)):\n","    for i, data in enumerate(dataloader):\n","        \n","        # Get the LR and HR images\n","        datalr = data[0].to(device)\n","        datahr = data[1].to(device)\n","        \n","        ############################\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        ###########################\n","        ## Train with all-real batch\n","        discriminator.zero_grad()\n","        # Format batch\n","        label = torch.full((datalr.size(0),), real_label, device=device)\n","        # Forward pass real batch through D\n","        output = discriminator(datahr).view(-1)\n","        # Calculate loss on all-real batch\n","        errD_real = criterion_GAN(output, label)\n","        # Calculate gradients for D in backward pass\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        ## Train with all-fake batch\n","        # Generate fake image batch with G\n","        fake = model(datalr)\n","        label.fill_(fake_label)\n","        # Classify all fake batch with D\n","        output = discriminator(fake.detach()).view(-1)\n","        # Calculate D's loss on the all-fake batch\n","        errD_fake = criterion_GAN(output, label)\n","        # Calculate the gradients for this batch\n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","        # Add the gradients from the all-real and all-fake batches\n","        errD = errD_real + errD_fake\n","        # Update D\n","        optimizer_D.step()\n","\n","        ############################\n","        # (2) Update G network: maximize log(D(G(z)))\n","        ###########################\n","        model.zero_grad()\n","        label.fill_(real_label)  # fake labels are real for generator cost\n","        # Since we just updated D, perform another forward pass of all-fake batch through D\n","        output = discriminator(fake).view(-1)\n","        # Calculate G's loss based on this output\n","        errG_GAN = criterion_GAN(output, label)\n","        # Calculate G's loss based on content\n","        errG_content = criterion_content(fake, datahr)\n","        # Calculate gradients for G\n","        errG = errG_GAN + errG_content\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","        # Update G\n","        optimizer_G.step()\n","\n","        '''\n","        # Output training stats\n","        if i % 50 == 0:\n","            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","                  % (epoch, n_epochs, i, len(dataloader),\n","                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","        '''\n","        \n","    # Save the models\n","    torch.save(model, './Weights/RCAN_GAN.pth')\n","    torch.save(discriminator, './Weights/RCAN_GAN_Discriminator.pth')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
