{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152342,"status":"ok","timestamp":1685583715722,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"uV8Lch-wnW32","outputId":"000d5e8e-6253-45aa-edc1-e24e65c0534d"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685583715723,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"Fltk46feoNyW","outputId":"2b88b487-3dcb-4011-c77f-71fd4da967b0"},"outputs":[],"source":["# cd drive/My \\Drive/....."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3980142,"status":"ok","timestamp":1685587695859,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"agXdpFwPPiHw","outputId":"6c5549c2-eed5-4b51-b2c2-af4492be3779"},"outputs":[],"source":["# Import required libraries\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from tqdm.notebook import tqdm\n","from torch import autograd\n","from torchvision import models\n","import torch.utils.model_zoo as model_zoo\n","import math\n","from skimage.metrics import structural_similarity as ssim\n","from sklearn.utils import shuffle\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Load training data\n","x_trainHR = np.load('./Data/train_HR.npy').astype(np.float32).reshape(-1,1,150,150) \n","x_trainLR = np.load('./Data/train_LR.npy').astype(np.float32).reshape(-1,1,75,75)\n","x_trainHR = torch.Tensor(x_trainHR)\n","x_trainLR = torch.Tensor(x_trainLR)\n","print(x_trainHR.shape)\n","print(x_trainLR.shape)\n","\n","dataset = TensorDataset(x_trainLR, x_trainHR)\n","dataloader = DataLoader(dataset, batch_size=8)\n","\n","# Channel Attention (CA) Layer\n","class CALayer(nn.Module):\n","    def __init__(self, channel, reduction=16):\n","        super(CALayer, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.ca = nn.Sequential(\n","                nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=True),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=True),\n","                nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        y = self.avg_pool(x)\n","        y = self.ca(y)\n","        return x * y\n","\n","# Residual Channel Attention Block (RCAB)\n","class RCAB(nn.Module):\n","    def __init__(self, channel, reduction=16):\n","        super(RCAB, self).__init__()\n","        self.body = nn.Sequential(\n","            nn.Conv2d(channel, channel, 3, 1, 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(channel, channel, 3, 1, 1),\n","            CALayer(channel, reduction)\n","        )\n","\n","    def forward(self, x):\n","        res = self.body(x)\n","        res += x\n","        return res\n","\n","# Residual Group (RG)\n","class RG(nn.Module):\n","    def __init__(self, channel, num_rcab, reduction):\n","        super(RG, self).__init__()\n","        modules_body = [RCAB(channel, reduction) for _ in range(num_rcab)]\n","        modules_body.append(nn.Conv2d(channel, channel, 3, padding=1))\n","        self.body = nn.Sequential(*modules_body)\n","\n","    def forward(self, x):\n","        res = self.body(x)\n","        res += x\n","        return res\n","\n","# Residual Channel Attention Network (RCAN)\n","class RCAN(nn.Module):\n","    def __init__(self, num_rg=2, num_rcab=4, num_channels=1, num_features=64, scale_factor=2, reduction=16):\n","        super(RCAN, self).__init__()\n","        self.sf = scale_factor\n","        self.num_features = num_features\n","\n","        self.head = nn.Conv2d(num_channels, num_features, 3, padding=1)\n","\n","        self.body = nn.Sequential(*[RG(num_features, num_rcab, reduction) for _ in range(num_rg)])\n","\n","        self.tail = nn.Sequential(\n","            nn.Conv2d(num_features, num_features, 3, padding=1),\n","            nn.Conv2d(num_features, num_channels * (scale_factor ** 2), 3, padding=1),\n","            nn.PixelShuffle(scale_factor)\n","        )\n","\n","    def forward(self, x):\n","        x = self.head(x)\n","        res = self.body(x)\n","        res += x\n","        x = self.tail(res)\n","        return x\n","\n","device = torch.device(\"cuda\")\n","model = RCAN().to(device)\n","\n","criteria = nn.L1Loss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n","\n","n_epochs = 30\n","\n","loss_array = []\n","for epoch in tqdm(range(1, n_epochs+1)):\n","    train_loss = 0.0\n","    for data in dataloader:\n","        datalr = data[0]\n","        datahr = data[1]\n","        datalr = datalr.to(device)\n","        datahr = datahr.to(device)\n","\n","        outputs = model(datalr)\n","        loss = criteria(outputs, datahr)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += (loss.item()*datahr.size(0))\n","\n","    train_loss = train_loss/x_trainHR.shape[0]\n","    loss_array.append(train_loss)\n","\n","    torch.save(model, './Weights/RCAN_MAE.pth')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
