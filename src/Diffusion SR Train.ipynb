{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uV8Lch-wnW32"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fltk46feoNyW"},"outputs":[],"source":["# cd drive/My \\Drive/....."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","id":"agXdpFwPPiHw"},"outputs":[],"source":["'''\n","Notebook to train DDPM for SR\n","'''\n","\n","# Import required libraries\n","import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","from torch import optim\n","import torchvision\n","from PIL import Image\n","from modules_conditional import UNet, Diffusion\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","def save_images(generated, conditional, path, **kwargs):\n","    # Convert to numpy arrays\n","    generated = generated.to('cpu').numpy()\n","    conditional = conditional.to('cpu').numpy()\n","\n","    # Create a figure and axes\n","    fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(20, 20))\n","\n","    # Adjust space between images\n","    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n","\n","    for i, (gen_img, cond_img) in enumerate(zip(generated, conditional)):\n","        row = i // 2\n","        col = (i % 2) * 2\n","\n","        # Conditional images\n","        axes[row, col].imshow(cond_img.squeeze(), cmap='gray', **kwargs)\n","        axes[row, col].axis('off')\n","        axes[row, col].set_title(f\"Conditional {i+1}\", fontsize=10, y=1.05)\n","\n","        # Generated images\n","        axes[row, col + 1].imshow(gen_img.squeeze(), cmap='gray', **kwargs)\n","        axes[row, col + 1].axis('off')\n","        axes[row, col + 1].set_title(f\"Generated {i+1}\", fontsize=10, y=1.05)\n","\n","    # Save the figure\n","    fig.savefig(path, bbox_inches='tight')\n","    plt.close(fig)\n","\n","# Load training data\n","# High-Resolution lensing data\n","x_trainHR = np.load('./Data/.../train_HR.npy').astype(np.float32).reshape(-1,1,64,64)\n","# Low-Resolution lensing data\n","x_trainLR = np.load('./Data/.../train_LR.npy').astype(np.float32).reshape(-1,1,64,64)\n","x_trainHR = torch.Tensor(x_trainHR)\n","x_trainLR = torch.Tensor(x_trainLR)\n","# Print data dimensions\n","print(x_trainHR.shape)\n","print(x_trainLR.shape)\n","\n","# Create dataset and dataloader for efficient data loading and batching\n","dataset = TensorDataset(x_trainHR,x_trainLR)\n","dataloader = DataLoader(dataset, batch_size=10)\n","\n","device = \"cuda\"\n","model = UNet().to(device)\n","#model.load_state_dict(torch.load('./Weights/Diff_ckpt_1.pt'))\n","optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n","mse = nn.MSELoss()\n","diffusion = Diffusion(img_size=64, device=device)\n","l = len(dataloader)\n","epochs = 100\n","\n","for epoch in range(1, epochs):\n","    print(f\"Starting epoch {epoch}:\")\n","    pbar = tqdm(dataloader)\n","    avg_mse = 0\n","    for i, (images, conditions) in enumerate(pbar):\n","        images = images.to(device)\n","        conditions = conditions.to(device)\n","        t = diffusion.sample_timesteps(images.shape[0]).to(device)\n","        x_t, noise = diffusion.noise_images(images, t)\n","        predicted_noise = model(x_t, t, conditions)\n","        loss = mse(noise, predicted_noise)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        pbar.set_postfix(MSE=loss.item())\n","        avg_mse += loss.item()\n","\n","    print(f'Average MSE: {avg_mse/1000:.5f}\\n')\n","    # sampled_images = diffusion.sample(model, n=images.shape[0], lat=conditions)\n","    # save_images(sampled_images, conditions, os.path.join(\"Results/Diff/Diff\", f\"{epoch}.png\"))\n","    torch.save(model.state_dict(), os.path.join(\"Weights\", f\"Diff_ckpt_1.pt\"))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
