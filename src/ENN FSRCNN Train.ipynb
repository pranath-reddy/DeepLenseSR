{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16173,"status":"ok","timestamp":1684984593489,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"uV8Lch-wnW32","outputId":"52cec6c8-80d6-4cdf-bfe0-aec02b89e76a"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":236,"status":"ok","timestamp":1684984593720,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"Fltk46feoNyW","outputId":"a3cd59b3-7d84-4ef0-feee-e7dc14a9e406"},"outputs":[],"source":["# cd drive/My \\Drive/....."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5849,"status":"ok","timestamp":1684984599565,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"6XvlT4a2JsSk","outputId":"39887748-bd38-4978-bbe2-a41c98baee3d"},"outputs":[],"source":["!pip3 install e2cnn"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["e045feab3b6544f5985a419e58bf3a1b","68260f2d7718436697434ab47a2e41c6","2612faee6b4e402381912a15fdbae5cd","2b3dc2d072b2462aaa7de9736bc524b5","3d7e9e568f8e46b78015edf0376b0978","ccf36c9cd55947549256965f949fcc06","b130a99af7e74661b4b2b5952d13d9b9","e8c6261c330e48a9bba5bd107244cdd8","685a49e9312b4918ad7c8920fa09fcb5","3fbeb934709d43458e2ea00d93f6150f","94b14d061e624b34b2c3a00f22baf51d"]},"executionInfo":{"elapsed":17499226,"status":"ok","timestamp":1685002098783,"user":{"displayName":"Pranath Reddy Kumbam","userId":"07194914569693395860"},"user_tz":240},"id":"agXdpFwPPiHw","outputId":"35bcb46e-1b49-4156-c27a-c6f20891a11d"},"outputs":[],"source":["'''\n","Pranath Reddy\n","Benchmark Notebook for Superresolution\n","Model: Equivariant FSRCNN\n","'''\n","\n","# Import required libraries\n","import torch\n","import numpy as np\n","#import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from tqdm.notebook import tqdm\n","from torch import autograd\n","from torchvision import models\n","import torch.utils.model_zoo as model_zoo\n","import math\n","from skimage.metrics import structural_similarity as ssim\n","from sklearn.utils import shuffle\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch\n","from e2cnn import gspaces\n","from e2cnn import nn\n","\n","# Load training data\n","# High-Resolution lensing data\n","x_trainHR = np.load('./Data/train_HR.npy').astype(np.float32).reshape(-1,1,150,150) \n","# Low-Resolution lensing data\n","x_trainLR = np.load('./Data/train_LR.npy').astype(np.float32).reshape(-1,1,75,75)\n","x_trainHR = torch.Tensor(x_trainHR)\n","x_trainLR = torch.Tensor(x_trainLR)\n","# Print data dimensions\n","print(x_trainHR.shape)\n","print(x_trainLR.shape)\n","\n","# Create dataset and dataloader for efficient data loading and batching\n","dataset = TensorDataset(x_trainLR, x_trainHR)\n","dataloader = DataLoader(dataset, batch_size=8)\n","\n","class Equivariant_FSRCNN(torch.nn.Module):\n","    \n","    def __init__(self, sym_group = \"Dihyderal\", N = 2, scale_factor=2, num_channels=1, d=16, s=64, m=4):\n","        \n","        super(Equivariant_FSRCNN, self).__init__()\n","        \n","        if sym_group == 'Dihyderal':\n","            self.r2_act = gspaces.FlipRot2dOnR2(N=N)\n","        elif sym_group == 'Circular':\n","            self.r2_act = gspaces.Rot2dOnR2(N=N)\n","            \n","        in_type = nn.FieldType(self.r2_act, num_channels*[self.r2_act.trivial_repr])\n","        self.input_type = in_type\n","\n","        out_type = nn.FieldType(self.r2_act, d*[self.r2_act.regular_repr])\n","        self.first_part = nn.SequentialModule(\n","            nn.MaskModule(in_type, 75, margin=1),\n","            nn.R2Conv(in_type, out_type, kernel_size=5, padding=5//2, bias=False),\n","            nn.InnerBatchNorm(out_type),\n","            nn.ReLU(out_type, inplace=True)\n","        )\n","        \n","        mid_part = []\n","        in_type = self.first_part.out_type\n","        out_type = nn.FieldType(self.r2_act, s*[self.r2_act.regular_repr])\n","        mid_part.extend([\n","            nn.R2Conv(in_type, out_type, kernel_size=1, bias=False),\n","            nn.InnerBatchNorm(out_type),\n","            nn.ReLU(out_type, inplace=True)\n","        ])\n","        for _ in range(m):\n","            in_type = out_type\n","            out_type = nn.FieldType(self.r2_act, s*[self.r2_act.regular_repr])\n","            mid_part.extend([\n","                nn.R2Conv(in_type, out_type, kernel_size=3, padding=3//2, bias=False),\n","                nn.InnerBatchNorm(out_type),\n","                nn.ReLU(out_type, inplace=True)\n","            ])\n","        self.mid_part = nn.SequentialModule(*mid_part)\n","\n","        in_type = self.mid_part.out_type\n","        out_type = nn.FieldType(self.r2_act, d*[self.r2_act.regular_repr])\n","        self.last_part = nn.SequentialModule(\n","            nn.R2Conv(in_type, out_type, kernel_size=1, bias=False),\n","            nn.InnerBatchNorm(out_type),\n","            nn.ReLU(out_type, inplace=True),\n","            nn.R2ConvTransposed(out_type, out_type, kernel_size=4, stride=scale_factor)\n","        )\n","\n","        in_type = self.last_part.out_type\n","        out_type = nn.FieldType(self.r2_act, 1*[self.r2_act.trivial_repr])\n","        self.final_layer = nn.SequentialModule(\n","            nn.R2Conv(in_type, out_type, kernel_size=3, padding=0, bias=False),\n","            nn.InnerBatchNorm(out_type),\n","            nn.ReLU(out_type, inplace=True)\n","        )\n","        \n","    def forward(self, input: torch.Tensor):\n","        x = nn.GeometricTensor(input, self.input_type)\n","        x = self.first_part(x)\n","        x = self.mid_part(x)\n","        x = self.last_part(x)\n","        x = self.final_layer(x)\n","        return x.tensor\n","       \n","device = torch.device(\"cuda\")\n","model = Equivariant_FSRCNN().to(device)\n","\n","# Set the loss criterion and optimizer\n","criteria = torch.nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n","\n","# Set the number of training epochs and learning rate scheduler\n","n_epochs = 50\n","scheduler = optim.lr_scheduler.OneCycleLR(optimizer, 2e-4, epochs=n_epochs, steps_per_epoch=x_trainHR.shape[0])\n","\n","# Training loop\n","loss_array = []\n","for epoch in tqdm(range(1, n_epochs+1)):\n","    train_loss = 0.0\n","    \n","    for data in dataloader:\n","\n","        # Fetch HR, LR data and pass to device\n","        datalr = data[0]\n","        datahr = data[1]\n","        datalr = datalr.to(device)\n","        datahr = datahr.to(device)\n","\n","        # Forward pass: compute predicted outputs by passing inputs to the model\n","        outputs = model(datalr)\n","        # Calculate the loss\n","        loss = criteria(outputs, datahr)\n","\n","        # Reset the gradients\n","        optimizer.zero_grad()\n","        # Perform a backward pass (backpropagation)\n","        loss.backward()\n","        # Update the parameters\n","        optimizer.step()\n","        # Update the learning rate\n","        scheduler.step()\n","\n","         # Update the training loss\n","        train_loss += (loss.item()*datahr.size(0))\n","        \n","    # Print average training statistics\n","    train_loss = train_loss/x_trainHR.shape[0]\n","    loss_array.append(train_loss)\n","\n","    # Save model and training loss\n","    torch.save(model.state_dict(), './Weights/EFSRCNN.pth')\n","    np.save('Results/EFSRCNN_Loss.npy', loss_array)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2612faee6b4e402381912a15fdbae5cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8c6261c330e48a9bba5bd107244cdd8","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_685a49e9312b4918ad7c8920fa09fcb5","value":50}},"2b3dc2d072b2462aaa7de9736bc524b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fbeb934709d43458e2ea00d93f6150f","placeholder":"â€‹","style":"IPY_MODEL_94b14d061e624b34b2c3a00f22baf51d","value":" 50/50 [4:50:51&lt;00:00, 347.28s/it]"}},"3d7e9e568f8e46b78015edf0376b0978":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fbeb934709d43458e2ea00d93f6150f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68260f2d7718436697434ab47a2e41c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccf36c9cd55947549256965f949fcc06","placeholder":"â€‹","style":"IPY_MODEL_b130a99af7e74661b4b2b5952d13d9b9","value":"100%"}},"685a49e9312b4918ad7c8920fa09fcb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94b14d061e624b34b2c3a00f22baf51d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b130a99af7e74661b4b2b5952d13d9b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccf36c9cd55947549256965f949fcc06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e045feab3b6544f5985a419e58bf3a1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68260f2d7718436697434ab47a2e41c6","IPY_MODEL_2612faee6b4e402381912a15fdbae5cd","IPY_MODEL_2b3dc2d072b2462aaa7de9736bc524b5"],"layout":"IPY_MODEL_3d7e9e568f8e46b78015edf0376b0978"}},"e8c6261c330e48a9bba5bd107244cdd8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
