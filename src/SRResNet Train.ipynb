{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uV8Lch-wnW32"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fltk46feoNyW"},"outputs":[],"source":["# cd drive/My \\Drive/....."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","id":"agXdpFwPPiHw"},"outputs":[],"source":["'''\n","Pranath Reddy\n","Benchmark Notebook for Superresolution\n","Model: SRResNet\n","'''\n","\n","# Import required libraries\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from tqdm.notebook import tqdm\n","from torch import autograd\n","from torchvision import models\n","import torch.utils.model_zoo as model_zoo\n","import math\n","from skimage.metrics import structural_similarity as ssim\n","from sklearn.utils import shuffle\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Load training data\n","# High-Resolution lensing data\n","x_trainHR = np.load('./Data/train_HR.npy').astype(np.float32).reshape(-1,1,150,150) \n","# Low-Resolution lensing data\n","x_trainLR = np.load('./Data/train_LR.npy').astype(np.float32).reshape(-1,1,75,75)\n","x_trainHR = torch.Tensor(x_trainHR)\n","x_trainLR = torch.Tensor(x_trainLR)\n","# Print data dimensions\n","print(x_trainHR.shape)\n","print(x_trainLR.shape)\n","\n","# Create dataset and dataloader for efficient data loading and batching\n","dataset = TensorDataset(x_trainLR, x_trainHR)\n","dataloader = DataLoader(dataset, batch_size=8)\n","\n","class Conv(nn.Module):\n","  def __init__(self, in_c, out_c, **kwargs):\n","      super().__init__()\n","      self.cnn = nn.Conv2d(in_c, out_c, **kwargs)\n","      self.actication = nn.PReLU(num_parameters=out_c)\n","\n","  def forward(self, x):\n","      x = self.cnn(x)\n","      x = self.actication(x)\n","      return x\n","\n","class Upsample(nn.Module):\n","  def __init__(self, in_c, scale_factor):\n","      super().__init__()\n","      self.conv = nn.Conv2d(in_c, in_c * scale_factor ** 2, kernel_size=3, stride=1, padding=1)\n","      self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n","      self.activation = nn.PReLU(num_parameters=in_c)\n","\n","  def forward(self, x):\n","      x = self.conv(x)\n","      x = self.pixel_shuffle(x)\n","      x = self.activation(x)\n","      return x\n","\n","class RBlock(nn.Module):\n","  def __init__(self, in_c):\n","      super().__init__()\n","      self.b1 = Conv(in_c, in_c, kernel_size=3, stride=1, padding=1)\n","      self.b2 = Conv(in_c, in_c, kernel_size=3, stride=1, padding=1)\n","\n","  def forward(self, x):\n","      b1_output = self.b1(x)\n","      b2_output = self.b2(b1_output)\n","      return b2_output + x\n","\n","class Generator(nn.Module):\n","  def __init__(self, in_c=1, out_c=64, no_blocks=18):\n","      super().__init__()\n","      self.first_conv = Conv(in_c, out_c, kernel_size=9, stride=1, padding=4)\n","      res_blocks = []\n","      for _ in range(no_blocks):\n","          res_blocks.append(RBlock(64))\n","      self.res_blocks = nn.Sequential(*res_blocks)\n","      self.conv1 = Conv(out_c, out_c, kernel_size=3, stride=1, padding=1)\n","\n","      self.upsampling = Upsample(out_c, scale_factor=2)\n","      self.last_conv = nn.Conv2d(out_c, in_c, kernel_size=3, stride=1, padding=1)\n","\n","  def forward(self,x):\n","      first_conv = self.first_conv(x)\n","      x = self.res_blocks(first_conv)\n","      x = self.conv1(x) + first_conv\n","      x = self.upsampling(x)\n","      x = self.last_conv(x)\n","      return x\n","     \n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = Generator().to(device)\n","model = model.to(device)\n","\n","# Set the loss criterion and optimizer\n","criteria = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n","\n","# Set the number of training epochs and learning rate scheduler\n","n_epochs = 50\n","scheduler = optim.lr_scheduler.OneCycleLR(optimizer, 2e-4, epochs=n_epochs, steps_per_epoch=x_trainHR.shape[0])\n","\n","# Training loop\n","loss_array = []\n","for epoch in tqdm(range(1, n_epochs+1)):\n","    train_loss = 0.0\n","    \n","    for data in dataloader:\n","\n","        # Fetch HR, LR data and pass to device\n","        datalr = data[0]\n","        datahr = data[1]\n","        datalr = datalr.to(device)\n","        datahr = datahr.to(device)\n","\n","        # Forward pass: compute predicted outputs by passing inputs to the model\n","        outputs = model(datalr)\n","        # Calculate the loss\n","        loss = criteria(outputs, datahr)\n","\n","        # Reset the gradients\n","        optimizer.zero_grad()\n","        # Perform a backward pass (backpropagation)\n","        loss.backward()\n","        # Update the parameters\n","        optimizer.step()\n","        # Update the learning rate\n","        scheduler.step()\n","\n","         # Update the training loss\n","        train_loss += (loss.item()*datahr.size(0))\n","        \n","    # Print average training statistics\n","    train_loss = train_loss/x_trainHR.shape[0]\n","    loss_array.append(train_loss)\n","\n","    # Save model and training loss\n","    torch.save(model, './Weights/SRResNet.pth')\n","    np.save('Results/SRResNet_Loss.npy', loss_array)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
