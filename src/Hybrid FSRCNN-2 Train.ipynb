{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uV8Lch-wnW32"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fltk46feoNyW"},"outputs":[],"source":["# cd drive/My \\Drive/....."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6XvlT4a2JsSk"},"outputs":[],"source":["!pip3 install e2cnn"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","id":"agXdpFwPPiHw"},"outputs":[],"source":["'''\n","Pranath Reddy\n","Benchmark Notebook for Superresolution\n","Model: Equivariant FSRCNN\n","'''\n","\n","# Import required libraries\n","import torch\n","import numpy as np\n","#import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from tqdm.notebook import tqdm\n","from torch import autograd\n","from torchvision import models\n","import torch.utils.model_zoo as model_zoo\n","import math\n","from skimage.metrics import structural_similarity as ssim\n","from sklearn.utils import shuffle\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch\n","from e2cnn import gspaces\n","from e2cnn import nn\n","\n","# Load training data\n","# High-Resolution lensing data\n","x_trainHR = np.load('./Data/train_HR.npy').astype(np.float32).reshape(-1,1,150,150) \n","# Low-Resolution lensing data\n","x_trainLR = np.load('./Data/train_LR.npy').astype(np.float32).reshape(-1,1,75,75)\n","x_trainHR = torch.Tensor(x_trainHR)\n","x_trainLR = torch.Tensor(x_trainLR)\n","# Print data dimensions\n","print(x_trainHR.shape)\n","print(x_trainLR.shape)\n","\n","# Create dataset and dataloader for efficient data loading and batching\n","dataset = TensorDataset(x_trainLR, x_trainHR)\n","dataloader = DataLoader(dataset, batch_size=8)\n","\n","class Equivariant_FSRCNN(torch.nn.Module):\n","    \n","    def __init__(self, sym_group = \"Dihyderal\", N = 2, scale_factor=2, num_channels=1, d=16, s=64, m=4):\n","        \n","        super(Equivariant_FSRCNN, self).__init__()\n","        \n","        if sym_group == 'Dihyderal':\n","            self.r2_act = gspaces.FlipRot2dOnR2(N=N)\n","        elif sym_group == 'Circular':\n","            self.r2_act = gspaces.Rot2dOnR2(N=N)\n","            \n","        in_type = nn.FieldType(self.r2_act, num_channels*[self.r2_act.trivial_repr])\n","        self.input_type = in_type\n","\n","        out_type = nn.FieldType(self.r2_act, d*[self.r2_act.regular_repr])\n","        self.first_part = nn.SequentialModule(\n","            nn.MaskModule(in_type, 75, margin=1),\n","            nn.R2Conv(in_type, out_type, kernel_size=5, padding=5//2, bias=False),\n","            nn.InnerBatchNorm(out_type),\n","            nn.ReLU(out_type, inplace=True)\n","        )\n","        \n","        mid_part = []\n","        in_type = self.first_part.out_type\n","        out_type = nn.FieldType(self.r2_act, s*[self.r2_act.regular_repr])\n","        mid_part.extend([\n","            nn.R2Conv(in_type, out_type, kernel_size=1, bias=False),\n","            nn.InnerBatchNorm(out_type),\n","            nn.ReLU(out_type, inplace=True)\n","        ])\n","        for _ in range(m):\n","            in_type = out_type\n","            out_type = nn.FieldType(self.r2_act, s*[self.r2_act.regular_repr])\n","            mid_part.extend([\n","                nn.R2Conv(in_type, out_type, kernel_size=3, padding=3//2, bias=False),\n","                nn.InnerBatchNorm(out_type),\n","                nn.ReLU(out_type, inplace=True)\n","            ])\n","        self.mid_part = nn.SequentialModule(*mid_part)\n","\n","        self.last_part = torch.nn.ConvTranspose2d(s*4, s, kernel_size=9, stride=scale_factor, padding=9//2,\n","                                            output_padding=scale_factor-1)\n","        \n","        self.conv5 = torch.nn.Conv2d(s, 64, 3, padding=1)\n","        self.conv6 = torch.nn.Conv2d(64, 128, 9, padding=4)\n","        self.conv7 = torch.nn.Conv2d(128, 32, 3, padding=1)\n","        self.conv8 = torch.nn.Conv2d(32, 32, 3, padding=1)\n","        self.conv9 = torch.nn.Conv2d(32, 1, 3, padding=1)\n","        self.relu = torch.nn.ReLU()\n","        \n","    def forward(self, input: torch.Tensor):\n","        x = nn.GeometricTensor(input, self.input_type)\n","        x = self.first_part(x)\n","        x = self.mid_part(x)\n","        x = x.tensor\n","        x = self.last_part(x)\n","        x = self.relu(self.conv5(x))\n","        x = self.relu(self.conv6(x))\n","        x = self.relu(self.conv7(x))\n","        x = self.relu(self.conv8(x))\n","        x = self.relu(self.conv9(x))\n","        return x \n","       \n","device = torch.device(\"cuda\")\n","model = Equivariant_FSRCNN().to(device)\n","\n","# Set the loss criterion and optimizer\n","criteria = torch.nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n","\n","# Set the number of training epochs and learning rate scheduler\n","n_epochs = 50\n","scheduler = optim.lr_scheduler.OneCycleLR(optimizer, 2e-4, epochs=n_epochs, steps_per_epoch=x_trainHR.shape[0])\n","\n","# Training loop\n","loss_array = []\n","for epoch in tqdm(range(1, n_epochs+1)):\n","    train_loss = 0.0\n","    \n","    for data in dataloader:\n","\n","        # Fetch HR, LR data and pass to device\n","        datalr = data[0]\n","        datahr = data[1]\n","        datalr = datalr.to(device)\n","        datahr = datahr.to(device)\n","\n","        # Forward pass: compute predicted outputs by passing inputs to the model\n","        outputs = model(datalr)\n","        # Calculate the loss\n","        loss = criteria(outputs, datahr)\n","\n","        # Reset the gradients\n","        optimizer.zero_grad()\n","        # Perform a backward pass (backpropagation)\n","        loss.backward()\n","        # Update the parameters\n","        optimizer.step()\n","        # Update the learning rate\n","        scheduler.step()\n","\n","         # Update the training loss\n","        train_loss += (loss.item()*datahr.size(0))\n","        \n","    # Print average training statistics\n","    train_loss = train_loss/x_trainHR.shape[0]\n","    loss_array.append(train_loss)\n","\n","    # Save model and training loss\n","    torch.save(model.state_dict(), './Weights/HFSRCNN-2.pth')\n","    np.save('Results/HFSRCNN-2_Loss.npy', loss_array)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
